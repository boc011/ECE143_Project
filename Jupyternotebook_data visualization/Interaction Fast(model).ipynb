{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fastFM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs5qFVSQka6S",
        "outputId": "fb79cee9-0e3d-480d-b311-82c3f2afe86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastFM\n",
            "  Downloading fastFM-0.2.10.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fastFM) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fastFM) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastFM) (1.11.4)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fastFM) (3.0.6)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastFM) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastFM) (3.2.0)\n",
            "Building wheels for collected packages: fastFM\n",
            "  Building wheel for fastFM (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastFM: filename=fastFM-0.2.10-cp310-cp310-linux_x86_64.whl size=591530 sha256=df5423e14174cc32773b5e07138193659221a0521f89080632355449878bdd51\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/92/52/2da7997fcb7a7ce9042ff3b33836ef0c2fd47aa95382d7a113\n",
            "Successfully built fastFM\n",
            "Installing collected packages: fastFM\n",
            "Successfully installed fastFM-0.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hincok3EmyeQ",
        "outputId": "2c50a3ed-bfc8-44c8-c974-a5605b8a7937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from fastFM import als, sgd, mcmc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler,label_binarize\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score, confusion_matrix\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse import hstack\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_dataset_path = \"/content/drive/MyDrive/AIHW/AS2/caius_data_clean.csv\""
      ],
      "metadata": {
        "id": "CTMT2ZzJnHDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = None\n",
        "if not os.path.exists(clean_dataset_path):\n",
        "  df = None\n",
        "  print(\"Empty Dataset\")\n",
        "else:\n",
        "  df = pd.read_csv(clean_dataset_path)"
      ],
      "metadata": {
        "id": "62nwwP-gnHV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_height = df['height'].dropna().mean()\n",
        "df['height'] = df['height'].fillna(average_height)\n",
        "df['height_mul'] = df['height']/10\n",
        "average_rating = df['rating'].dropna().mean()\n",
        "df['rating'] = df['rating'].fillna(average_rating)\n",
        "df['size_mul'] = df['size']*2"
      ],
      "metadata": {
        "id": "QH66mSdeoIhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder()\n",
        "categorical_data = encoder.fit_transform(df[['user_id', 'item_id']])\n",
        "scaler = StandardScaler()\n",
        "numerical_data = scaler.fit_transform(df[['size','rating','height']])\n",
        "# Increase all size_mul by 3 times\n",
        "for i in range(len(numerical_data)):\n",
        "  numerical_data[i][0] = numerical_data[i][0]*4"
      ],
      "metadata": {
        "id": "TqvlsVnqndKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BYziJzq-DQr",
        "outputId": "299e0ffe-ea83-40aa-d53b-8262d8e87a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.6197251 ,  0.63482249,  1.01150603],\n",
              "       [-0.08658481,  0.63482249,  0.25928317],\n",
              "       [-2.91182445,  0.63482249, -0.4929397 ],\n",
              "       ...,\n",
              "       [-1.49920463, -2.16289696,  1.01150603],\n",
              "       [ 1.32603501,  0.63482249,  0.25928317],\n",
              "       [ 1.32603501,  0.63482249,  0.25928317]])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized data preparation\n",
        "# Define the resampling strategy\n",
        "#X = hstack([categorical_data, height_data])\n",
        "X = hstack([categorical_data,numerical_data])\n",
        "fit_mapping = {'small': 0, 'fit': 1, 'large': 2}\n",
        "y = df['fit'].map(fit_mapping).values\n",
        "over = SMOTE(sampling_strategy={0: int(len(y) * 0.5), 2: int(len(y) * 0.5)}, k_neighbors=3)\n",
        "under = RandomUnderSampler(sampling_strategy={1: int(len(y) * 0.4)})\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
        "# Define the pipeline\n",
        "# pipeline = Pipeline(steps=[('o', over), ('u', under)])\n",
        "pipeline = Pipeline(steps=[('o', over)])\n",
        "y_binary = label_binarize(y, classes=np.unique(y),neg_label=-1)\n",
        "# Apply the pipeline to your data\n",
        "X_train, y_train = pipeline.fit_resample(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "fp1RPnlh0Hr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X = hstack([categorical_data, height_data])\n",
        "#Size only\n",
        "X = categorical_data\n",
        "# Binarize target variable for One-vs-Rest strategy\n",
        "fit_mapping = {'small': 0, 'fit': 1, 'large': 2}\n",
        "y = df['fit'].map(fit_mapping).values\n",
        "y_binary = label_binarize(y, classes=np.unique(y),neg_label=-1)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.1)"
      ],
      "metadata": {
        "id": "NMecOVC8nnCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FMClassifier(als.FMClassification):\n",
        "    def fit(self, X, y, *args):\n",
        "        y = y.copy()\n",
        "        y[y == 0] = -1\n",
        "        return super(FMClassifier, self).fit(X, y, *args)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        probs = super(FMClassifier, self).predict_proba(X)\n",
        "        return np.tile(probs, 2).reshape(2, probs.shape[0]).T\n",
        "\n",
        "ovr_classifier = OneVsRestClassifier(FMClassifier(n_iter=150,init_stdev=0.2, rank=4, l2_reg_w=0.3, l2_reg_V=0.3), n_jobs=-1)\n",
        "\n",
        "# Initialize the factorization machine model\n",
        "# fm_model = als.FMClassification(n_iter=25, init_stdev=0.1, rank=2, l2_reg_w=0.1, l2_reg_V=0.1)\n",
        "\n",
        "# Apply One-vs-Rest strategy for multiclass prediction\n",
        "# ovr_classifier = OneVsRestClassifier(fm_model)\n",
        "\n",
        "# Fit the model\n",
        "ovr_classifier.fit(csr_matrix(X_train), y_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "x7pRoVAzuCsh",
        "outputId": "83be3a1e-c26b-48ca-88e0-975f011b7859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=FMClassifier(init_stdev=0.2, l2_reg_V=0.3,\n",
              "                                           l2_reg_w=0.3, n_iter=150, rank=4),\n",
              "                    n_jobs=-1)"
            ],
            "text/html": [
              "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=FMClassifier(init_stdev=0.2, l2_reg_V=0.3,\n",
              "                                           l2_reg_w=0.3, n_iter=150, rank=4),\n",
              "                    n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=FMClassifier(init_stdev=0.2, l2_reg_V=0.3,\n",
              "                                           l2_reg_w=0.3, n_iter=150, rank=4),\n",
              "                    n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: FMClassifier</label><div class=\"sk-toggleable__content\"><pre>FMClassifier(init_stdev=0.2, l2_reg_V=0.3, l2_reg_w=0.3, n_iter=150, rank=4)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FMClassifier</label><div class=\"sk-toggleable__content\"><pre>FMClassifier(init_stdev=0.2, l2_reg_V=0.3, l2_reg_w=0.3, n_iter=150, rank=4)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the probabilities\n",
        "y_pred_prob = ovr_classifier.predict_proba(csr_matrix(X_test))\n",
        "y_pred = ovr_classifier.predict(X_test)\n",
        "# Calculate AUC for each class and average\n",
        "auc_scores = roc_auc_score(y_test, y_pred_prob, average='macro', multi_class='ovr')\n",
        "\n",
        "print(f'AUC Scores: {auc_scores}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYPF5NsGvDT8",
        "outputId": "701a4211-0611-4311-8a94-117dee95cf15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Scores: 0.7110919100222474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_count=0\n",
        "fit_count=0\n",
        "large_count=0\n",
        "for i in range(len(y_pred_prob)):\n",
        "  if y_pred_prob[i][0]>y_pred_prob[i][1] and y_pred_prob[i][0]>y_pred_prob[i][2]:\n",
        "    small_count+=1\n",
        "  elif y_pred_prob[i][1]>y_pred_prob[i][0] and y_pred_prob[i][1]>y_pred_prob[i][2]:\n",
        "    fit_count+=1\n",
        "  else:\n",
        "    large_count+=1\n",
        "\n",
        "print(small_count)\n",
        "print(fit_count)\n",
        "print(large_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0VxJfQRxnBR",
        "outputId": "a70e268c-d6e0-4fde-fadc-4a72575fd470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2265\n",
            "15011\n",
            "1979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_acc = 0\n",
        "fit_acc = 0\n",
        "large_acc = 0\n",
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i]==0 and y_test[i]==0:\n",
        "    small_acc+=1\n",
        "  elif y_pred[i]==1 and y_test[i]==1:\n",
        "    fit_acc+=1\n",
        "  elif y_pred[i]==2 and y_test[i]==2:\n",
        "    large_acc+=1\n",
        "\n",
        "print(small_acc)\n",
        "print(fit_acc)\n",
        "print(large_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTo66wNyxvsH",
        "outputId": "f87fd39d-1889-4cfc-9c47-ce56c8dfc6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "867\n",
            "11971\n",
            "716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_small = 0\n",
        "true_fit = 0\n",
        "true_large = 0\n",
        "for i in range(len(y_pred)):\n",
        "  if y_test[i]==0:\n",
        "    true_small+=1\n",
        "  elif y_test[i]==1:\n",
        "    true_fit+=1\n",
        "  elif y_test[i]==2:\n",
        "    true_large+=1"
      ],
      "metadata": {
        "id": "lz1ZxuuFfrtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test, y_pred, target_names=['Small', 'Fit', 'Large'])\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3HGrQE-6Cv6",
        "outputId": "5efbd37d-80a0-42ca-ad86-19478e24b679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Small       0.38      0.34      0.36      2539\n",
            "         Fit       0.80      0.84      0.82     14307\n",
            "       Large       0.36      0.30      0.33      2409\n",
            "\n",
            "    accuracy                           0.70     19255\n",
            "   macro avg       0.51      0.49      0.50     19255\n",
            "weighted avg       0.69      0.70      0.70     19255\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In the top 73% data, how many are with label 1\n",
        "def getTopNPositive(percentile,label,prob_list,test_data):\n",
        "  # Convert inputs to numpy arrays if they aren't already\n",
        "    prob_list = np.array(prob_list)\n",
        "    test_data = np.array(test_data)\n",
        "\n",
        "    # Step 1: Sort predictions for the specified label and get indices\n",
        "    sorted_indices = np.argsort(prob_list[:, label])[::-1]\n",
        "\n",
        "    # Step 2: Select top N% of the records\n",
        "    top_n_percent = int(len(prob_list) * (percentile / 100))\n",
        "    selected_indices = sorted_indices[:top_n_percent]\n",
        "\n",
        "    # Step 3: Fetch the corresponding true labels\n",
        "    selected_true_labels = test_data[selected_indices]\n",
        "\n",
        "    # Step 4: Count how many of these are actually labeled as the specified label\n",
        "    correct_predictions = np.sum(selected_true_labels == label)\n",
        "\n",
        "    return correct_predictions/top_n_percent"
      ],
      "metadata": {
        "id": "-iFIipuBzT-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getTopNPositive(73,1,y_pred_prob,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhLJ6QZs01B5",
        "outputId": "c81b776e-d353-41f2-aaaa-e82fb7b67387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8032157085941947"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_list = np.array(y_pred_prob)\n",
        "test_data = np.array(y_test)\n",
        "sorted_indices = np.argsort(prob_list[:,1])[::-1]\n",
        "top_n_percent = int(len(prob_list) * (73 / 100))\n",
        "selected_indices = sorted_indices[top_n_percent:]\n",
        "selected_labels = test_data[selected_indices]\n",
        "selected_prob  = prob_list[selected_indices]\n",
        "new_label = []\n",
        "for i,_ in enumerate(selected_prob):\n",
        "  large_prob = selected_prob[i][2]\n",
        "  small_prob = selected_prob[i][0]\n",
        "  if large_prob >= small_prob:\n",
        "    new_label.append(2)\n",
        "  else:\n",
        "    new_label.append(0)\n",
        "print(classification_report(selected_labels, new_label, target_names=['Small', 'Fit', 'Large']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOh0Hj9p2ABe",
        "outputId": "80855094-2f3d-4d9c-ab67-c12029923e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Small       0.36      0.81      0.50      1166\n",
            "         Fit       0.00      0.00      0.00      3017\n",
            "       Large       0.34      0.85      0.48      1016\n",
            "\n",
            "    accuracy                           0.35      5199\n",
            "   macro avg       0.23      0.55      0.33      5199\n",
            "weighted avg       0.15      0.35      0.21      5199\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, find the indices where the true label is not 'fit' (1) but the predicted label is 'fit' (1)\n",
        "incorrect_fit_indices = np.where((y_test != 1) & (y_pred == 1))\n",
        "\n",
        "# Extract the probabilities for these specific cases\n",
        "# This gives you the probabilities assigned to 'fit' for the wrongly predicted samples\n",
        "incorrect_fit_probabilities = y_pred_prob[incorrect_fit_indices]\n",
        "incorrect_labels = y_test[incorrect_fit_indices]\n",
        "\n"
      ],
      "metadata": {
        "id": "aya6xj8F2Tpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6chE0__32nTA",
        "outputId": "f76ad955-8f2e-42b2-c15e-f4d64924ac9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 2, ..., 0, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_fit_probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOOlMDAU2aL8",
        "outputId": "3559b01a-772c-4137-d502-9cc211e8407b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20672657, 0.54707572, 0.24619771],\n",
              "       [0.30585778, 0.35216067, 0.34198155],\n",
              "       [0.23117969, 0.55653585, 0.21228445],\n",
              "       ...,\n",
              "       [0.28701327, 0.47474297, 0.23824376],\n",
              "       [0.21918853, 0.4986673 , 0.28214417],\n",
              "       [0.21588637, 0.44564624, 0.3384674 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_test is your true labels and y_pred_labels is your predicted labels\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# The diagonal elements of the confusion matrix correspond to correct predictions (true positives)\n",
        "# For each class, divide the true positive count by the total actual instances of that class (the sum of the corresponding row in the confusion matrix)\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "\n",
        "# Now class_accuracies[i] will give you the accuracy for class i\n",
        "for i, accuracy in enumerate(class_accuracies):\n",
        "    print(f'Accuracy for class {i}: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMnvC4nh6tkG",
        "outputId": "b076b3ee-8e0e-4ca6-fc9e-2ccb5440c9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class 0: 0.39\n",
            "Accuracy for class 1: 0.70\n",
            "Accuracy for class 2: 0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getAcc(y_t,y_p):\n",
        "  conf_matrix = confusion_matrix(y_t, y_p)\n",
        "  class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=0)\n",
        "  return class_accuracies"
      ],
      "metadata": {
        "id": "6DRCr7iM7dfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getAcc(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdvRc5aG7lKB",
        "outputId": "f3932b41-e89b-4d89-cb28-b9d7cd5baf14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3162446 , 0.79555059, 0.31588032])"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f4pTDE8b9Hot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0.0, 0.5, 0.005)\n",
        "fit_thresh = np.arange(0.3,0.8,0.01)\n",
        "best_t = 1.0\n",
        "best_fit_t = 0.0\n",
        "best_acc = 0\n",
        "for fit_thresh in fit_thresh:\n",
        "  for thresh in t:\n",
        "    new_labels = []\n",
        "    for i in range(len(y_pred_prob)):\n",
        "      large_prob = y_pred_prob[i][2]\n",
        "      fit_prob = y_pred_prob[i][1]\n",
        "      small_prob = y_pred_prob[i][0]\n",
        "      # Originally fit\n",
        "      if fit_prob > small_prob and fit_prob > large_prob:\n",
        "        if fit_prob > fit_thresh:\n",
        "          new_labels.append(1)\n",
        "          continue\n",
        "        if large_prob > small_prob:\n",
        "          if large_prob + thresh > fit_prob:\n",
        "            new_labels.append(2)\n",
        "          else:\n",
        "            new_labels.append(1)\n",
        "        else:\n",
        "          if small_prob + thresh > fit_prob:\n",
        "            new_labels.append(0)\n",
        "          else:\n",
        "            new_labels.append(1)\n",
        "      else:\n",
        "        if large_prob > small_prob:\n",
        "          new_labels.append(2)\n",
        "        else:\n",
        "          new_labels.append(0)\n",
        "    acc = getAcc(y_test,new_labels)\n",
        "    print(acc)\n",
        "    print(f'Threshold: {thresh}, Accuracy: {acc}', f'Fit Threshold: {fit_thresh}')"
      ],
      "metadata": {
        "id": "aPAHc_of4dEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for thresh in t:\n",
        "  new_labels = []\n",
        "  for i in range(len(incorrect_fit_probabilities)):\n",
        "    large_prob = incorrect_fit_probabilities[i][2]\n",
        "    fit_prob = incorrect_fit_probabilities[i][1]\n",
        "    small_prob = incorrect_fit_probabilities[i][0]\n",
        "    if large_prob > small_prob:\n",
        "      if large_prob * thresh > fit_prob:\n",
        "        new_labels.append(2)\n",
        "      else:\n",
        "        new_labels.append(1)\n",
        "    else:\n",
        "      if small_prob * thresh > fit_prob:\n",
        "        new_labels.append(0)\n",
        "      else:\n",
        "        new_labels.append(1)\n",
        "  acc = accuracy_score(incorrect_labels, new_labels)\n",
        "  if acc > best_acc:\n",
        "    best_t = thresh\n",
        "    best_acc = acc\n",
        "    print(f'Threshold: {thresh}, Accuracy: {acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhP5Cl413Ch1",
        "outputId": "3083e3b4-78c6-4cf8-d554-3864dac1e8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold: 1.05, Accuracy: 0.0655226209048362\n",
            "Threshold: 1.1, Accuracy: 0.1294851794071763\n",
            "Threshold: 1.1500000000000001, Accuracy: 0.1829173166926677\n",
            "Threshold: 1.2000000000000002, Accuracy: 0.2421996879875195\n",
            "Threshold: 1.2500000000000002, Accuracy: 0.2878315132605304\n",
            "Threshold: 1.3000000000000003, Accuracy: 0.3408736349453978\n",
            "Threshold: 1.3500000000000003, Accuracy: 0.37753510140405616\n",
            "Threshold: 1.4000000000000004, Accuracy: 0.41809672386895474\n",
            "Threshold: 1.4500000000000004, Accuracy: 0.4539781591263651\n",
            "Threshold: 1.5000000000000004, Accuracy: 0.484009360374415\n",
            "Threshold: 1.5500000000000005, Accuracy: 0.516380655226209\n",
            "Threshold: 1.6000000000000005, Accuracy: 0.5444617784711389\n",
            "Threshold: 1.6500000000000006, Accuracy: 0.5717628705148206\n",
            "Threshold: 1.7000000000000006, Accuracy: 0.5873634945397815\n",
            "Threshold: 1.7500000000000007, Accuracy: 0.6045241809672387\n",
            "Threshold: 1.8000000000000007, Accuracy: 0.6197347893915757\n",
            "Threshold: 1.8500000000000008, Accuracy: 0.6333853354134166\n",
            "Threshold: 1.9000000000000008, Accuracy: 0.641185647425897\n",
            "Threshold: 1.9500000000000008, Accuracy: 0.6509360374414976\n",
            "Threshold: 2.000000000000001, Accuracy: 0.6602964118564743\n",
            "Threshold: 2.0500000000000007, Accuracy: 0.6673166926677067\n",
            "Threshold: 2.100000000000001, Accuracy: 0.6735569422776911\n",
            "Threshold: 2.1500000000000012, Accuracy: 0.6770670826833073\n",
            "Threshold: 2.200000000000001, Accuracy: 0.6813572542901716\n",
            "Threshold: 2.250000000000001, Accuracy: 0.6860374414976599\n",
            "Threshold: 2.300000000000001, Accuracy: 0.6875975039001561\n",
            "Threshold: 2.3500000000000014, Accuracy: 0.6895475819032761\n",
            "Threshold: 2.4000000000000012, Accuracy: 0.6918876755070202\n",
            "Threshold: 2.450000000000001, Accuracy: 0.6934477379095164\n",
            "Threshold: 2.5000000000000013, Accuracy: 0.6965678627145085\n",
            "Threshold: 2.5500000000000016, Accuracy: 0.6985179407176287\n",
            "Threshold: 2.6000000000000014, Accuracy: 0.7000780031201248\n",
            "Threshold: 2.6500000000000012, Accuracy: 0.7004680187207488\n",
            "Threshold: 2.7000000000000015, Accuracy: 0.7008580343213728\n",
            "Threshold: 2.7500000000000018, Accuracy: 0.7020280811232449\n",
            "Threshold: 2.8000000000000016, Accuracy: 0.702808112324493\n",
            "Threshold: 2.8500000000000014, Accuracy: 0.7035881435257411\n",
            "Threshold: 2.9000000000000017, Accuracy: 0.7043681747269891\n",
            "Threshold: 2.950000000000002, Accuracy: 0.7047581903276131\n"
          ]
        }
      ]
    }
  ]
}